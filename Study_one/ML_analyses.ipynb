{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_train_R2: 0.16520199683349482\n",
      "average_train_MSE: 127.91212178299577\n",
      "average_train_MAE: 8.866787149322397\n",
      "\n",
      "average_test_R2: 0.10103277367638963\n",
      "average_test_MSE: 137.18853000591912\n",
      "average_test_MAE: 9.170173167048162\n",
      "\n",
      "average_syn_R2: 0.06290046788187435\n",
      "average_syn_MSE: 144.0185448249643\n",
      "average_syn_MAE: 9.547253402074178\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "original_data = pd.read_csv('data/original_data.csv')\n",
    "synthetic_data = pd.read_csv('data/synthetic_data.csv')\n",
    "\n",
    "categorical_features = ['SEX', 'ETHGP']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "X = original_data.drop('CRFIN', axis=1)\n",
    "y = original_data['CRFIN']\n",
    "X_synthetic = preprocessor.fit_transform(synthetic_data.drop('CRFIN', axis=1))\n",
    "y_synthetic = synthetic_data['CRFIN']\n",
    "\n",
    "# define K-Fold\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "scores = {\n",
    "    'train_r2': [],\n",
    "    'train_mse': [],\n",
    "    'train_mae': [],\n",
    "    \n",
    "    'test_r2': [],\n",
    "    'test_mse': [],\n",
    "    'test_mae': [],\n",
    "\n",
    "    'synthetic_r2': [],\n",
    "    'synthetic_mse': [],\n",
    "    'synthetic_mae': []\n",
    "}\n",
    "\n",
    "# K-Fold \n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # preprocess\n",
    "    X_train_encoded = preprocessor.fit_transform(X_train)\n",
    "    X_test_encoded = preprocessor.transform(X_test)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        max_depth=1, \n",
    "        learning_rate=0.05,\n",
    "        n_estimators=100,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.01,\n",
    "        reg_lambda=1 # L2 regularization\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "\n",
    "    # train\n",
    "    train_preds = model.predict(X_train_encoded)\n",
    "    scores['train_r2'].append(r2_score(y_train, train_preds))\n",
    "    scores['train_mse'].append(mean_squared_error(y_train, train_preds))\n",
    "    scores['train_mae'].append(mean_absolute_error(y_train, train_preds))\n",
    "\n",
    "    # test\n",
    "    test_preds = model.predict(X_test_encoded)\n",
    "    scores['test_r2'].append(r2_score(y_test, test_preds))\n",
    "    scores['test_mse'].append(mean_squared_error(y_test, test_preds))\n",
    "    scores['test_mae'].append(mean_absolute_error(y_test, test_preds))\n",
    "\n",
    "    # syn\n",
    "    synthetic_preds = model.predict(X_synthetic)\n",
    "    scores['synthetic_r2'].append(r2_score(y_synthetic, synthetic_preds))\n",
    "    scores['synthetic_mse'].append(mean_squared_error(y_synthetic, synthetic_preds))\n",
    "    scores['synthetic_mae'].append(mean_absolute_error(y_synthetic, synthetic_preds))\n",
    "\n",
    "# print\n",
    "print(\"average_train_R2:\", np.mean(scores['train_r2']))\n",
    "print(\"average_train_MSE:\", np.mean(scores['train_mse']))\n",
    "print(\"average_train_MAE:\", np.mean(scores['train_mae']))\n",
    "\n",
    "print(\"\\naverage_test_R2:\", np.mean(scores['test_r2']))\n",
    "print(\"average_test_MSE:\", np.mean(scores['test_mse']))\n",
    "print(\"average_test_MAE:\", np.mean(scores['test_mae']))\n",
    "\n",
    "print(\"\\naverage_syn_R2:\", np.mean(scores['synthetic_r2']))\n",
    "print(\"average_syn_MSE:\", np.mean(scores['synthetic_mse']))\n",
    "print(\"average_syn_MAE:\", np.mean(scores['synthetic_mae']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_train_R2: 0.18424996923223938\n",
      "average_train_MSE: 124.98970011843429\n",
      "average_train_MAE: 8.785449268351341\n",
      "\n",
      "average_test_R2: 0.08907896436779202\n",
      "average_test_MSE: 139.03768182922892\n",
      "average_test_MAE: 9.274475409292446\n",
      "\n",
      "average_syn_R2: 0.07330053030054447\n",
      "average_syn_MSE: 142.4202067570323\n",
      "average_syn_MAE: 9.49164071195605\n"
     ]
    }
   ],
   "source": [
    "# Catboost\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "original_data = pd.read_csv('data/original_data.csv')\n",
    "synthetic_data = pd.read_csv('data/synthetic_data.csv')\n",
    "\n",
    "X = original_data.drop('CRFIN', axis=1)\n",
    "y = original_data['CRFIN']\n",
    "X_synthetic = synthetic_data.drop('CRFIN', axis=1)\n",
    "y_synthetic = synthetic_data['CRFIN']\n",
    "\n",
    "categorical_features_indices = [X.columns.get_loc(col) for col in ['SEX', 'ETHGP']]\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "scores = {\n",
    "    'train_r2': [],\n",
    "    'train_mse': [],\n",
    "    'train_mae': [],\n",
    "    'test_r2': [],\n",
    "    'test_mse': [],\n",
    "    'test_mae': [],\n",
    "    'synthetic_r2': [],\n",
    "    'synthetic_mse': [],\n",
    "    'synthetic_mae': []\n",
    "}\n",
    "\n",
    "# K-Fold \n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=100,\n",
    "        learning_rate=0.05,\n",
    "        depth=3, \n",
    "        loss_function='RMSE',\n",
    "        verbose=False,\n",
    "        cat_features=categorical_features_indices,\n",
    "        l2_leaf_reg=10,\n",
    "        subsample=0.8\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_preds = model.predict(X_train)\n",
    "    scores['train_r2'].append(r2_score(y_train, train_preds))\n",
    "    scores['train_mse'].append(mean_squared_error(y_train, train_preds))\n",
    "    scores['train_mae'].append(mean_absolute_error(y_train, train_preds))\n",
    "\n",
    "    test_preds = model.predict(X_test)\n",
    "    scores['test_r2'].append(r2_score(y_test, test_preds))\n",
    "    scores['test_mse'].append(mean_squared_error(y_test, test_preds))\n",
    "    scores['test_mae'].append(mean_absolute_error(y_test, test_preds))\n",
    "\n",
    "    synthetic_preds = model.predict(X_synthetic)\n",
    "    scores['synthetic_r2'].append(r2_score(y_synthetic, synthetic_preds))\n",
    "    scores['synthetic_mse'].append(mean_squared_error(y_synthetic, synthetic_preds))\n",
    "    scores['synthetic_mae'].append(mean_absolute_error(y_synthetic, synthetic_preds))\n",
    "\n",
    "print(\"average_train_R2:\", np.mean(scores['train_r2']))\n",
    "print(\"average_train_MSE:\", np.mean(scores['train_mse']))\n",
    "print(\"average_train_MAE:\", np.mean(scores['train_mae']))\n",
    "\n",
    "print(\"\\naverage_test_R2:\", np.mean(scores['test_r2']))\n",
    "print(\"average_test_MSE:\", np.mean(scores['test_mse']))\n",
    "print(\"average_test_MAE:\", np.mean(scores['test_mae']))\n",
    "\n",
    "print(\"\\naverage_syn_R2:\", np.mean(scores['synthetic_r2']))\n",
    "print(\"average_syn_MSE:\", np.mean(scores['synthetic_mse']))\n",
    "print(\"average_syn_MAE:\", np.mean(scores['synthetic_mae']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_train_R2: 0.1725967891483908\n",
      "average_train_MSE: 126.7695318891721\n",
      "average_train_MAE: 8.838799457915867\n",
      "\n",
      "average_test_R2: 0.0904079290002161\n",
      "average_test_MSE: 138.8447022222304\n",
      "average_test_MAE: 9.263940561146024\n",
      "\n",
      "average_syn_R2: 0.061437932398678965\n",
      "average_syn_MSE: 144.24331522002424\n",
      "average_syn_MAE: 9.537745898618706\n"
     ]
    }
   ],
   "source": [
    "# Random forest\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "original_data = pd.read_csv('data/original_data.csv')\n",
    "synthetic_data = pd.read_csv('data/synthetic_data.csv')\n",
    "\n",
    "categorical_features = ['SEX', 'ETHGP']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "X_original = original_data.drop('CRFIN', axis=1)\n",
    "y_original = original_data['CRFIN'].values\n",
    "X_synthetic = synthetic_data.drop('CRFIN', axis=1)\n",
    "y_synthetic = synthetic_data['CRFIN'].values\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "scores = {\n",
    "    'train_r2': [],\n",
    "    'train_mse': [],\n",
    "    'train_mae': [],\n",
    "    'test_r2': [],\n",
    "    'test_mse': [],\n",
    "    'test_mae': [],\n",
    "    'synthetic_r2': [],\n",
    "    'synthetic_mse': [],\n",
    "    'synthetic_mae': []\n",
    "}\n",
    "\n",
    "for train_index, test_index in kf.split(X_original):\n",
    "    X_train, X_test = X_original.iloc[train_index], X_original.iloc[test_index]\n",
    "    y_train, y_test = y_original[train_index], y_original[test_index]\n",
    "    \n",
    "    X_train_encoded = preprocessor.fit_transform(X_train)\n",
    "    X_test_encoded = preprocessor.transform(X_test)\n",
    "    X_synthetic_encoded = preprocessor.transform(X_synthetic)\n",
    "    \n",
    "    random_forest_model = RandomForestRegressor(\n",
    "        n_estimators=100,  \n",
    "        min_samples_split=50,  \n",
    "        min_samples_leaf=50,  \n",
    "        random_state=42\n",
    "    )\n",
    "    random_forest_model.fit(X_train_encoded, y_train)\n",
    "\n",
    "    train_predictions = random_forest_model.predict(X_train_encoded)\n",
    "    scores['train_r2'].append(r2_score(y_train, train_predictions))\n",
    "    scores['train_mse'].append(mean_squared_error(y_train, train_predictions))\n",
    "    scores['train_mae'].append(mean_absolute_error(y_train, train_predictions))\n",
    "\n",
    "    test_predictions = random_forest_model.predict(X_test_encoded)\n",
    "    scores['test_r2'].append(r2_score(y_test, test_predictions))\n",
    "    scores['test_mse'].append(mean_squared_error(y_test, test_predictions))\n",
    "    scores['test_mae'].append(mean_absolute_error(y_test, test_predictions))\n",
    "\n",
    "    synthetic_predictions = random_forest_model.predict(X_synthetic_encoded)\n",
    "    scores['synthetic_r2'].append(r2_score(y_synthetic, synthetic_predictions))\n",
    "    scores['synthetic_mse'].append(mean_squared_error(y_synthetic, synthetic_predictions))\n",
    "    scores['synthetic_mae'].append(mean_absolute_error(y_synthetic, synthetic_predictions))\n",
    "\n",
    "print(\"average_train_R2:\", np.mean(scores['train_r2']))\n",
    "print(\"average_train_MSE:\", np.mean(scores['train_mse']))\n",
    "print(\"average_train_MAE:\", np.mean(scores['train_mae']))\n",
    "\n",
    "print(\"\\naverage_test_R2:\", np.mean(scores['test_r2']))\n",
    "print(\"average_test_MSE:\", np.mean(scores['test_mse']))\n",
    "print(\"average_test_MAE:\", np.mean(scores['test_mae']))\n",
    "\n",
    "print(\"\\naverage_syn_R2:\", np.mean(scores['synthetic_r2']))\n",
    "print(\"average_syn_MSE:\", np.mean(scores['synthetic_mse']))\n",
    "print(\"average_syn_MAE:\", np.mean(scores['synthetic_mae']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 568\n",
      "[LightGBM] [Info] Number of data points in the train set: 844, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 83.759479\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 564\n",
      "[LightGBM] [Info] Number of data points in the train set: 845, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 83.704142\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 561\n",
      "[LightGBM] [Info] Number of data points in the train set: 845, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 83.736095\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 561\n",
      "[LightGBM] [Info] Number of data points in the train set: 845, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 83.686391\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 562\n",
      "[LightGBM] [Info] Number of data points in the train set: 845, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 83.404734\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "average_train_R2: 0.20303513053753894\n",
      "average_train_MSE: 122.1177644384137\n",
      "average_train_MAE: 8.671654506421254\n",
      "\n",
      "average_test_R2: 0.08616022162175938\n",
      "average_test_MSE: 139.59991455491735\n",
      "average_test_MAE: 9.32309439311661\n",
      "\n",
      "average_syn_R2: 0.07184109930005438\n",
      "average_syn_MSE: 142.6445000383318\n",
      "average_syn_MAE: 9.472413322360746\n"
     ]
    }
   ],
   "source": [
    "# LGBMRegressor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "original_data = pd.read_csv('data/original_data.csv')\n",
    "synthetic_data = pd.read_csv('data/synthetic_data.csv')\n",
    "\n",
    "categorical_features = ['SEX', 'ETHGP']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "X_original = original_data.drop('CRFIN', axis=1)\n",
    "y_original = original_data['CRFIN'].values\n",
    "X_synthetic = synthetic_data.drop('CRFIN', axis=1)\n",
    "y_synthetic = synthetic_data['CRFIN'].values\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "scores = {\n",
    "    'train_r2': [],\n",
    "    'train_mse': [],\n",
    "    'train_mae': [],\n",
    "    'test_r2': [],\n",
    "    'test_mse': [],\n",
    "    'test_mae': [],\n",
    "    'synthetic_r2': [],\n",
    "    'synthetic_mse': [],\n",
    "    'synthetic_mae': []\n",
    "}\n",
    "\n",
    "for train_index, test_index in kf.split(X_original):\n",
    "    X_train, X_test = X_original.iloc[train_index], X_original.iloc[test_index]\n",
    "    y_train, y_test = y_original[train_index], y_original[test_index]\n",
    "    \n",
    "    X_train_encoded = preprocessor.fit_transform(X_train)\n",
    "    X_test_encoded = preprocessor.transform(X_test)\n",
    "    X_synthetic_encoded = preprocessor.transform(X_synthetic)\n",
    "\n",
    "    lgbm_model = LGBMRegressor(\n",
    "        objective='regression',\n",
    "        num_leaves=15,\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=100,\n",
    "        lambda_l1=0.01,\n",
    "        lambda_l2=1,\n",
    "        min_data_in_leaf=30,\n",
    "        min_sum_hessian_in_leaf=1e-3,\n",
    "        bagging_fraction=0.8,\n",
    "        bagging_freq=5, \n",
    "        feature_fraction=0.8,\n",
    "    )\n",
    "    \n",
    "    lgbm_model.fit(X_train_encoded, y_train)\n",
    "\n",
    "    train_predictions = lgbm_model.predict(X_train_encoded)\n",
    "    scores['train_r2'].append(r2_score(y_train, train_predictions))\n",
    "    scores['train_mse'].append(mean_squared_error(y_train, train_predictions))\n",
    "    scores['train_mae'].append(mean_absolute_error(y_train, train_predictions))\n",
    "\n",
    "    test_predictions = lgbm_model.predict(X_test_encoded)\n",
    "    scores['test_r2'].append(r2_score(y_test, test_predictions))\n",
    "    scores['test_mse'].append(mean_squared_error(y_test, test_predictions))\n",
    "    scores['test_mae'].append(mean_absolute_error(y_test, test_predictions))\n",
    "\n",
    "    synthetic_predictions = lgbm_model.predict(X_synthetic_encoded)\n",
    "    scores['synthetic_r2'].append(r2_score(y_synthetic, synthetic_predictions))\n",
    "    scores['synthetic_mse'].append(mean_squared_error(y_synthetic, synthetic_predictions))\n",
    "    scores['synthetic_mae'].append(mean_absolute_error(y_synthetic, synthetic_predictions))\n",
    "\n",
    "print(\"average_train_R2:\", np.mean(scores['train_r2']))\n",
    "print(\"average_train_MSE:\", np.mean(scores['train_mse']))\n",
    "print(\"average_train_MAE:\", np.mean(scores['train_mae']))\n",
    "\n",
    "print(\"\\naverage_test_R2:\", np.mean(scores['test_r2']))\n",
    "print(\"average_test_MSE:\", np.mean(scores['test_mse']))\n",
    "print(\"average_test_MAE:\", np.mean(scores['test_mae']))\n",
    "\n",
    "print(\"\\naverage_syn_R2:\", np.mean(scores['synthetic_r2']))\n",
    "print(\"average_syn_MSE:\", np.mean(scores['synthetic_mse']))\n",
    "print(\"average_syn_MAE:\", np.mean(scores['synthetic_mae']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
