{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load the original data\n",
    "original_data = pd.read_csv('Boston.csv')\n",
    "\n",
    "# Check\n",
    "print(\"Original Data:\")\n",
    "print(original_data.head())\n",
    "\n",
    "# Check the metadata/data structure\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(original_data)\n",
    "print(metadata)\n",
    "\n",
    "# Define batch sizes and epochs to test\n",
    "batch_sizes = [200, 300, 500]\n",
    "epochs_list = [1000, 2000, 3000, 5000]\n",
    "batch_epoch_combinations = list(itertools.product(batch_sizes, epochs_list))\n",
    "\n",
    "# Function to evaluate the synthetic data quality\n",
    "def evaluate_synthetic_data(original_data, synthetic_data):\n",
    "    # Example evaluation using mean absolute error\n",
    "    errors = []\n",
    "    for col in original_data.columns:\n",
    "        if original_data[col].dtype in [np.float64, np.int64]:\n",
    "            error = np.mean(np.abs(original_data[col] - synthetic_data[col]))\n",
    "            errors.append(error)\n",
    "    return np.mean(errors)\n",
    "\n",
    "best_model = None\n",
    "best_score = float('inf')\n",
    "best_params = None\n",
    "\n",
    "# Loop over each combination of batch size and epochs\n",
    "for batch_size, epochs in batch_epoch_combinations:\n",
    "    try:\n",
    "        print(f\"Training model with batch_size={batch_size}, epochs={epochs}\")\n",
    "        \n",
    "        synthesizer = CTGANSynthesizer(\n",
    "            metadata, \n",
    "            enforce_min_max_values=True,\n",
    "            enforce_rounding=True,\n",
    "            batch_size=batch_size, \n",
    "            epochs=epochs, \n",
    "            verbose=True,\n",
    "            cuda=True  # Set to False if CUDA is not available\n",
    "        )\n",
    "        \n",
    "        # Fit the synthesizer to the original data and generate synthetic data\n",
    "        synthesizer.fit(original_data)\n",
    "        synthetic_data = synthesizer.sample(len(original_data))\n",
    "\n",
    "        # Evaluate the synthetic data\n",
    "        score = evaluate_synthetic_data(original_data, synthetic_data)\n",
    "        print(f\"Score for batch_size={batch_size}, epochs={epochs}: {score}\")\n",
    "        \n",
    "        # Check if this model is the best so far\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_model = synthesizer\n",
    "            best_params = (batch_size, epochs)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for batch_size={batch_size}, epochs={epochs}: {e}\")\n",
    "\n",
    "# Save the best model\n",
    "if best_model is not None:\n",
    "    best_model_filename = f\"best_model_bs{best_params[0]}_ep{best_params[1]}.pkl\"\n",
    "    with open(best_model_filename, 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    print(f\"Best model saved as {best_model_filename}\")\n",
    "\n",
    "    # Save the synthetic data from the best model\n",
    "    synthetic_data = best_model.sample(len(original_data))\n",
    "    synthetic_data.to_csv('synthetic_data.csv', index=False)\n",
    "    print(\"Best synthetic data generated and saved to 'synthetic_data.csv'\")\n",
    "else:\n",
    "    print(\"No valid model was trained.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Evaluation\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.evaluation.single_table import run_diagnostic\n",
    "from sdv.evaluation.single_table import evaluate_quality\n",
    "from sdv.evaluation.single_table import get_column_pair_plot\n",
    "import pandas as pd\n",
    "\n",
    "# Here, we do some evaluation to see how well the synthetic data matches the original data\n",
    "original_data = pd.read_csv('Boston.csv')\n",
    "synthetic_data = pd.read_csv('synthetic_data.csv')\n",
    "\n",
    "original_data.keys()\n",
    "\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(original_data)\n",
    "\n",
    "# Here is check the data types of the columns and data structure.\n",
    "diagnostic = run_diagnostic(\n",
    "    real_data=original_data,\n",
    "    synthetic_data=synthetic_data,\n",
    "    metadata=metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we check how close the two data is. Score close to 1 is good.\n",
    "quality_report = evaluate_quality(\n",
    "    original_data,\n",
    "    synthetic_data,\n",
    "    metadata\n",
    ")\n",
    "\n",
    "quality_report.get_details(property_name='Column Shapes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we check how can the privacy be reserved in the synthetic data\n",
    "\n",
    "# Find overlapping rows\n",
    "overlapping_data = pd.merge(original_data, synthetic_data, how='inner')\n",
    "\n",
    "# Display the overlapping rows\n",
    "print(\"Overlapping data:\")\n",
    "print(overlapping_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_30.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we show the distribution of selected columns in the original and synthetic data\n",
    "\n",
    "fig = get_column_pair_plot(\n",
    "    real_data=original_data,\n",
    "    synthetic_data=synthetic_data,\n",
    "    metadata=metadata,\n",
    "    column_names=['rm', 'dis'],\n",
    "    )\n",
    "    \n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
